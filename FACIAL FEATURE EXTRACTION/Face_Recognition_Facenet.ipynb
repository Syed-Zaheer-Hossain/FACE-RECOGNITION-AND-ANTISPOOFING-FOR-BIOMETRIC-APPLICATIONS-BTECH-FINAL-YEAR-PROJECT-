{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc6263-476e-438d-bbc1-a04ebfbb9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Sep 20 19:58:59 2023\n",
    "\n",
    "@author: SYED ZAHEER HOSSAIN\n",
    "\"\"\"\n",
    "\n",
    "# Importing necessary libraries\n",
    "from keras_facenet import FaceNet\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Initialize the FaceNet embedder\n",
    "embedder = FaceNet()\n",
    "\n",
    "# Path to the \"preprocessed\" folder\n",
    "# base_dir = 'E:\\DATA PREPROCESS/preprocessed'\n",
    "# base_dir = \"E:\\MACHINE LEARNING\\dataraw100\"\n",
    "base_dir = \"E:/dataset all combined/comb-preprocessed\"\n",
    "# base_dir = \"E:\\MACHINE LEARNING\\output2\"\n",
    "output_dir = \"E:\\MACHINE LEARNING\\CSV_Final_233\"\n",
    "original = \"original\"\n",
    "\n",
    "#code for calculation of time\n",
    "\n",
    "start = time.time()\n",
    "timetot=[]\n",
    "timet = [\"No. of images\" , \"Time Taken\"]\n",
    "timetot.append(timet)\n",
    "\n",
    "counter = add = 30\n",
    "j=0\n",
    "\n",
    "\n",
    "# Initialize lists to store face embeddings and corresponding labels for training and testing\n",
    "train_embeddings = []\n",
    "train_labels = []\n",
    "test_embeddings = []\n",
    "test_labels = []\n",
    "\n",
    "z=1\n",
    "no = 30\n",
    "# crop = \"cropped\"\n",
    "crop = \"cropped\"\n",
    "\n",
    "# Create the csv output folder if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "subfolders = os.listdir(base_dir)\n",
    "for subdir in subfolders:\n",
    "    if(z):\n",
    "        z+=1\n",
    "        subdir_path = os.path.join(base_dir, subdir, original)\n",
    "        if os.path.isdir(subdir_path):  # Check if it's a directory\n",
    "            image_paths = [os.path.join(subdir_path, filename) for filename in os.listdir(subdir_path)]\n",
    "            \n",
    "            # split image paths into training and testing datasets with a 50-50 ratio\n",
    "            train_paths, test_paths = train_test_split(image_paths, test_size=0.5, random_state=42)\n",
    "            \n",
    "            # Initialize embedding lists for training and testing\n",
    "            train_embeddings_subfolder = []\n",
    "            test_embeddings_subfolder = []\n",
    "            \n",
    "            # Embed images for training\n",
    "            for image_path in train_paths:\n",
    "                # image = Image.open(image_path)\n",
    "                \n",
    "                # Convert PIL Image to NumPy array\n",
    "                # image_array = np.array(image)\n",
    "                image_array = cv2.imread(image_path)\n",
    "                image_array = cv2.resize(image_array,(100,100))\n",
    "                \n",
    "                # Embed the image and append to training embeddings\n",
    "                embedding = embedder.embeddings([image_array])[0]\n",
    "                image_size = image_array.shape\n",
    "                train_embeddings_subfolder.append(embedding)\n",
    "                train_labels.append(subdir)\n",
    "                \n",
    "                print(j)\n",
    "                j=j+1\n",
    "                \n",
    "                if(j == counter):\n",
    "                    timet=[]\n",
    "                    end = time.time()\n",
    "                    tott = end - start\n",
    "                    timet.append(counter)\n",
    "                    timet.append(tott)\n",
    "                    timetot.append(timet)\n",
    "                    counter += add\n",
    "                    print(tott)\n",
    "            \n",
    "            # Embed images for testing\n",
    "            for image_path in test_paths:\n",
    "                # image = Image.open(image_path)\n",
    "                \n",
    "                # Convert PIL Image to NumPy array\n",
    "                # image_array = np.array(image)\n",
    "                image_array = cv2.imread(image_path)\n",
    "                image_array = cv2.resize(image_array,(100,100))\n",
    "                \n",
    "                # Embed the image and append to testing embeddings\n",
    "                embedding = embedder.embeddings([image_array])[0]\n",
    "                test_embeddings_subfolder.append(embedding)\n",
    "                test_labels.append(subdir)\n",
    "                \n",
    "                print(j)\n",
    "                j=j+1\n",
    "                \n",
    "                if(j == counter):\n",
    "                    timet=[]\n",
    "                    end = time.time()\n",
    "                    tott = end - start\n",
    "                    timet.append(counter)\n",
    "                    timet.append(tott)\n",
    "                    timetot.append(timet)\n",
    "                    counter += add\n",
    "                    print(tott)\n",
    "        \n",
    "        # Append subfolder embeddings to the main training and testing lists\n",
    "        train_embeddings.extend(train_embeddings_subfolder)\n",
    "        test_embeddings.extend(test_embeddings_subfolder)\n",
    "\n",
    "# Convert embeddings and labels to DataFrames for training and testing\n",
    "train_embeddings_df = pd.DataFrame(train_embeddings)\n",
    "train_labels_df = pd.DataFrame(train_labels, columns=['label'])\n",
    "test_embeddings_df = pd.DataFrame(test_embeddings)\n",
    "test_labels_df = pd.DataFrame(test_labels, columns=['label'])\n",
    "\n",
    "# Concatenate embeddings and labels DataFrames for training and testing\n",
    "train_result_df = pd.concat([train_embeddings_df, train_labels_df], axis=1)\n",
    "test_result_df = pd.concat([test_embeddings_df, test_labels_df], axis=1)\n",
    "\n",
    "# Save embeddings and labels of the training dataset to a CSV file\n",
    "output_train_csv_path = os.path.join(output_dir,f\"facenet_train_embeddings_{crop}_{z-1}.csv\")\n",
    "train_result_df.to_csv(output_train_csv_path, index=False)\n",
    "print(f\"Training embeddings saved to {output_train_csv_path}\")\n",
    "\n",
    "# Save embeddings and labels of the testing dataset to a CSV file\n",
    "output_test_csv_path = os.path.join(output_dir,f\"facenet_test_embeddings_{crop}_{z-1}.csv\")\n",
    "test_result_df.to_csv(output_test_csv_path, index=False)\n",
    "print(f\"Testing embeddings saved to {output_test_csv_path}\")\n",
    "\n",
    "# Load training embeddings and labels from CSV\n",
    "train_embeddings_df = pd.read_csv(output_train_csv_path)\n",
    "trainX = train_embeddings_df.drop(columns=['label']).values\n",
    "trainy = train_embeddings_df['label'].values\n",
    "\n",
    "# Load testing embeddings and labels from CSV\n",
    "test_embeddings_df = pd.read_csv(output_test_csv_path)\n",
    "testX = test_embeddings_df.drop(columns=['label']).values\n",
    "testy = test_embeddings_df['label'].values\n",
    "\n",
    "# Normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "\n",
    "# Label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "\n",
    "# SVM classifier with a radial basis function kernel\n",
    "svm_model = SVC(kernel='rbf', probability=True)\n",
    "svm_model.fit(trainX, trainy)\n",
    "yhat_train_svm = svm_model.predict(trainX)\n",
    "yhat_test_svm = svm_model.predict(testX)\n",
    "accuracy_train_svm = accuracy_score(trainy, yhat_train_svm)\n",
    "accuracy_test_svm = accuracy_score(testy, yhat_test_svm)\n",
    "print('SVM Accuracy: train=%.3f, test=%.3f' % (accuracy_train_svm * 100, accuracy_test_svm * 100))\n",
    "\n",
    "\n",
    "#code for calculation of time\n",
    "\n",
    "end = time.time()\n",
    "tott = end - start\n",
    "\n",
    "#code for calculation of time\n",
    "\n",
    "end = time.time()\n",
    "tott = end - start\n",
    "\n",
    "avg = (tott / (no*12))\n",
    "\n",
    "print(f\"Average time for image processing is {avg}\")\n",
    "print(f\"size of dataset image is {image_size}\")\n",
    "\n",
    "# timet=[]\n",
    "# timet.append(j)\n",
    "# timet.append(tott)\n",
    "# timetot.append(timet)\n",
    " \n",
    "# pd.DataFrame(timetot).to_csv(\"E:\\MACHINE LEARNING\\IMAGE PROCESSING/facetime.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
